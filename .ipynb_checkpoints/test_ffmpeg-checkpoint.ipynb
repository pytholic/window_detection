{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd7dfee",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62e63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e5452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# def set_device():\n",
    "#     if torch.cuda.is_available():\n",
    "#         dev = \"cuda:0\"\n",
    "#     else:\n",
    "#         dev = \"cpu\"\n",
    "#     return torch.device(dev)\n",
    "\n",
    "# device = set_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa137cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "model_path = './model/best_model.pth'\n",
    "video_path = \"./test2.mp4\"\n",
    "NUM_CLASSES = 2\n",
    "WIDTH = 1920\n",
    "HEIGHT = 1080\n",
    "classes = ['open', 'close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5a7fa",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9046c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(3, 32, 5) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        \n",
    "        x = torch.randn(3,224,224).view(-1,3,224,224)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, NUM_CLASSES)\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        if NUM_CLASSES == 2:\n",
    "            return F.sigmoid(x)\n",
    "        else:\n",
    "            return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c2ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c54ef4",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to apply transforms\n",
    "def get_transform():\n",
    "    resize = T.Resize((224,224))\n",
    "    mean = (127.5)\n",
    "    std = (127.5)\n",
    "    normalize = T.Normalize(mean=mean, std=std)\n",
    "    return T.Compose([resize, normalize])\n",
    "\n",
    "# Print function (for testing)\n",
    "def print_text(\n",
    "    img,\n",
    "    text: str,\n",
    "    org=(100, 100),\n",
    "    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    fontScale=1.5,\n",
    "    color=(0, 255, 0),\n",
    "    thickness=2,\n",
    "):\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text,\n",
    "        org=org,\n",
    "        fontFace=fontFace,\n",
    "        fontScale=fontScale,\n",
    "        color=color,\n",
    "        thickness=thickness,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae0a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def classify(model, image_transforms, img, classes):\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.permute(2, 0, 1)    \n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.float()\n",
    "    img = image_transforms(img)\n",
    "\n",
    "    output = model(img)\n",
    "    _, prediction = torch.max(output.data, 1)\n",
    "    predicted_class = classes[prediction.item()]\n",
    "            \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df12cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pytholic/anaconda3/envs/window_detection/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "workdir = os.getcwd()\n",
    "command = ['ffmpeg', \n",
    "           '-i', f'{video_path}', \n",
    "           '-f', 'image2pipe',\n",
    "           '-pix_fmt', 'rgb24',\n",
    "           '-vcodec', 'rawvideo', '-']\n",
    "\n",
    "process = sp.Popen(command, stderr=sp.PIPE, stdout=sp.PIPE)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ### INPUT ###\n",
    "    arr = np.frombuffer(process.stdout.read(WIDTH*HEIGHT*3), dtype=np.uint8)\n",
    "    \n",
    "    if len(arr) == 0:\n",
    "        break\n",
    "        \n",
    "    frame = arr.reshape((HEIGHT,WIDTH,3))    \n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    ### PREDICTION ###\n",
    "    \n",
    "    # Crop the image\n",
    "    img_right = img[300:900, 1450:1700]\n",
    "    img_left = cv2.flip(img, 1)\n",
    "    img_left = img_left[300:900, 1450:1700] \n",
    "    result_right = classify(model, get_transform(), img_right, classes)\n",
    "    result_left = classify(model, get_transform(), img_left, classes)\n",
    "    \n",
    "    print_text(img, str(result_right), org=(1600,400))\n",
    "    print_text(img, str(result_left), org=(300,400))\n",
    "    \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:  # wait for ESC key to exit\n",
    "        break\n",
    "        \n",
    "    process.stdout.flush()\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a60184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973a9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
